{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7e2f2a4-69a4-4847-9946-59797fdc2a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01aa974a-a9f1-4990-909a-a6ed737e2fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Menghilangkan karakter non-alfanumerik dan mengganti beberapa karakter\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Opsi tambahan: mengganti newline dengan spasi, dll.\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba99a4af-d5aa-4667-9c53-82ac608aa528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inisialisasi Tokenizer mBERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "971e9cd1-cf88-4ca5-9b0b-5b1df40d3d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sliding_window_tokenize(text, max_length=512, stride=50):\n",
    "    # Konversi teks ke token dan inisialisasi segmen\n",
    "    initial_tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    total_tokens = len(initial_tokens)\n",
    "    window_segments = []\n",
    "\n",
    "    if total_tokens <= max_length:\n",
    "        # Jika total token kurang dari max_length, tidak perlu sliding window\n",
    "        return [tokenizer.encode(text, add_special_tokens=True)]\n",
    "\n",
    "    for i in range(0, total_tokens, stride):\n",
    "        # Memilih segmen token dengan mempertimbangkan token spesial\n",
    "        window_segment = [tokenizer.cls_token_id] + initial_tokens[i:i + max_length - 2] + [tokenizer.sep_token_id]\n",
    "        window_segments.append(window_segment)\n",
    "\n",
    "    return window_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5bc89ac-f6d7-45e4-a0e5-9b4cebd917b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk menggabungkan token menjadi string\n",
    "def tokens_to_string(tokens):\n",
    "    return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60f45589-fdad-4149-9745-3326115eb480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Memuat dataset\n",
    "df = pd.read_csv('Merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6c98dce-40d1-4eb9-9afc-8c8d3098c757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Pembersihan teks\n",
    "df['cleaned_OCR_text'] = df['OCR_Text'].apply(clean_text)\n",
    "# Sliding window tokenization\n",
    "df['tokenized_segments'] = df['cleaned_OCR_text'].apply(sliding_window_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4020cbd0-cf0a-4a74-9137-b724f36c8a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Padding dan Attention Mask\n",
    "MAX_LEN = 512\n",
    "\n",
    "def pad_segments(segments):\n",
    "    return pad_sequences(segments, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "def create_attention_masks(padded_segments):\n",
    "    return np.where(padded_segments != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ffdb256-3928-49ea-8cea-cf664c413763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['padded_segments'] = df['tokenized_segments'].apply(pad_segments)\n",
    "df['attention_masks'] = df['padded_segments'].apply(create_attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2b8279c-2bc4-49cf-a0e7-a01022e4f8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Memuat model mBERT\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased').to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34c75b0b-19b8-40d7-a7a6-94f6d40f5f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk mengolah segmen dengan mBERT\n",
    "def bert_encode(segments, attention_mask):\n",
    "    input_ids = torch.tensor(segments).type(torch.LongTensor)\n",
    "    attention_mask = torch.tensor(attention_mask).type(torch.LongTensor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    return last_hidden_states[0][:, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a35449-76ad-48a9-9ab5-523625ff98e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mengolah setiap baris data dengan mBERT\n",
    "df['bert_features'] = df.apply(lambda row: bert_encode(row['padded_segments'], row['attention_masks']), axis=1)\n",
    "# Rata-ratakan vektor fitur\n",
    "df['average_bert_features'] = df['bert_features'].apply(lambda x: np.mean(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21032595-f4d6-477b-9a8a-cff4c2647e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyiapkan label\n",
    "df['encoded_label'] = df['Label'].apply(lambda x: 1 if x == 'Fraud' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d850bfa-6c53-41b0-bcba-198fddd5331f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
