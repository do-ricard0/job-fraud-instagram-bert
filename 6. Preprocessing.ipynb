{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.1.1-cp38-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /Users/ricardo/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from torch) (2023.12.0)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/ricardo/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: filelock in /Users/ricardo/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from torch) (3.13.1)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /Users/ricardo/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, jinja2, torch\n",
      "Successfully installed jinja2-3.1.2 mpmath-1.3.0 networkx-3.1 sympy-1.12 torch-2.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7e2f2a4-69a4-4847-9946-59797fdc2a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01aa974a-a9f1-4990-909a-a6ed737e2fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Menghilangkan karakter non-alfanumerik dan mengganti beberapa karakter\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Opsi tambahan: mengganti newline dengan spasi, dll.\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba99a4af-d5aa-4667-9c53-82ac608aa528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 11.0kB/s]\n",
      "vocab.txt: 100%|██████████| 996k/996k [00:01<00:00, 603kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.96M/1.96M [00:01<00:00, 1.30MB/s]\n",
      "config.json: 100%|██████████| 625/625 [00:00<00:00, 329kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi Tokenizer mBERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "971e9cd1-cf88-4ca5-9b0b-5b1df40d3d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sliding_window_tokenize(text, max_length=512, stride=50):\n",
    "    # Konversi teks ke token dan inisialisasi segmen\n",
    "    initial_tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    total_tokens = len(initial_tokens)\n",
    "    window_segments = []\n",
    "\n",
    "    if total_tokens <= max_length:\n",
    "        # Jika total token kurang dari max_length, tidak perlu sliding window\n",
    "        return [tokenizer.encode(text, add_special_tokens=True)]\n",
    "\n",
    "    for i in range(0, total_tokens, stride):\n",
    "        # Memilih segmen token dengan mempertimbangkan token spesial\n",
    "        window_segment = [tokenizer.cls_token_id] + initial_tokens[i:i + max_length - 2] + [tokenizer.sep_token_id]\n",
    "        window_segments.append(window_segment)\n",
    "\n",
    "    return window_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5bc89ac-f6d7-45e4-a0e5-9b4cebd917b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk menggabungkan token menjadi string\n",
    "def tokens_to_string(tokens):\n",
    "    return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60f45589-fdad-4149-9745-3326115eb480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Memuat dataset\n",
    "df = pd.read_csv('Merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6c98dce-40d1-4eb9-9afc-8c8d3098c757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pembersihan teks\n",
    "df['cleaned_OCR_text'] = df['OCR_Text'].apply(clean_text)\n",
    "# Sliding window tokenization\n",
    "df['tokenized_segments'] = df['cleaned_OCR_text'].apply(sliding_window_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4020cbd0-cf0a-4a74-9137-b724f36c8a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Padding dan Attention Mask\n",
    "MAX_LEN = 512\n",
    "\n",
    "def pad_segments(segments):\n",
    "    return pad_sequences(segments, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "def create_attention_masks(padded_segments):\n",
    "    return np.where(padded_segments != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ffdb256-3928-49ea-8cea-cf664c413763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['padded_segments'] = df['tokenized_segments'].apply(pad_segments)\n",
    "df['attention_masks'] = df['padded_segments'].apply(create_attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2b8279c-2bc4-49cf-a0e7-a01022e4f8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 714M/714M [03:30<00:00, 3.39MB/s] \n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Memuat model mBERT\n",
    "model = TFBertModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34c75b0b-19b8-40d7-a7a6-94f6d40f5f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk mengolah segmen dengan mBERT\n",
    "def bert_encode(segments, attention_mask):\n",
    "    input_ids = tf.constant(segments)\n",
    "    attention_mask = tf.constant(attention_mask)\n",
    "\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    return last_hidden_states[0][:, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2a35449-76ad-48a9-9ab5-523625ff98e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ricardo/Project/job-fraud-instagram-bert/6. Preprocessing.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Mengolah setiap baris data dengan mBERT\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mbert_features\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m row: bert_encode(row[\u001b[39m'\u001b[39;49m\u001b[39mpadded_segments\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mattention_masks\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Rata-ratakan vektor fitur\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39maverage_bert_features\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mbert_features\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39mmean(x, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/Users/ricardo/Project/job-fraud-instagram-bert/6. Preprocessing.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Mengolah setiap baris data dengan mBERT\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mbert_features\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: bert_encode(row[\u001b[39m'\u001b[39;49m\u001b[39mpadded_segments\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mattention_masks\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Rata-ratakan vektor fitur\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39maverage_bert_features\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mbert_features\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39mmean(x, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n",
      "\u001b[1;32m/Users/ricardo/Project/job-fraud-instagram-bert/6. Preprocessing.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m input_ids \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(segments)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m attention_mask \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(attention_mask)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m last_hidden_states \u001b[39m=\u001b[39m model(input_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ricardo/Project/job-fraud-instagram-bert/6.%20Preprocessing.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m last_hidden_states[\u001b[39m0\u001b[39m][:, \u001b[39m0\u001b[39m, :]\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/engine/training.py:569\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    567\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[0;32m--> 569\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49munpacked_inputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/transformers/models/bert/modeling_tf_bert.py:1088\u001b[0m, in \u001b[0;36mTFBertModel.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[39m@unpack_inputs\u001b[39m\n\u001b[1;32m   1045\u001b[0m \u001b[39m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mbatch_size, sequence_length\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   1046\u001b[0m \u001b[39m@add_code_sample_docstrings\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     training: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1067\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[TFBaseModelOutputWithPoolingAndCrossAttentions, Tuple[tf\u001b[39m.\u001b[39mTensor]]:\n\u001b[1;32m   1068\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[39m    encoder_hidden_states  (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[39m        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[39m        `past_key_values`). Set to `False` during training, `True` during generation\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1089\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1090\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1091\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1092\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1093\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1094\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1095\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1096\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1097\u001b[0m         past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1098\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1099\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1100\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1101\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1102\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   1103\u001b[0m     )\n\u001b[1;32m   1104\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49munpacked_inputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/transformers/models/bert/modeling_tf_bert.py:862\u001b[0m, in \u001b[0;36mTFBertMainLayer.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    860\u001b[0m     head_mask \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers\n\u001b[0;32m--> 862\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    863\u001b[0m     hidden_states\u001b[39m=\u001b[39;49membedding_output,\n\u001b[1;32m    864\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    865\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    866\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    867\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    868\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    869\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    870\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    871\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    872\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    873\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m    874\u001b[0m )\n\u001b[1;32m    876\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    877\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(hidden_states\u001b[39m=\u001b[39msequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/transformers/models/bert/modeling_tf_bert.py:554\u001b[0m, in \u001b[0;36mTFBertEncoder.call\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    550\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[1;32m    552\u001b[0m past_key_value \u001b[39m=\u001b[39m past_key_values[i] \u001b[39mif\u001b[39;00m past_key_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    555\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    556\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    557\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m    558\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    559\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    560\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    561\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    562\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    564\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    566\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/transformers/models/bert/modeling_tf_bert.py:464\u001b[0m, in \u001b[0;36mTFBertLayer.call\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\n\u001b[1;32m    452\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m     hidden_states: tf\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    461\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[tf\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    465\u001b[0m         input_tensor\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    466\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    467\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    468\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    469\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    470\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    471\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    472\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m    473\u001b[0m     )\n\u001b[1;32m    474\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    476\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/transformers/models/bert/modeling_tf_bert.py:380\u001b[0m, in \u001b[0;36mTFBertAttention.call\u001b[0;34m(self, input_tensor, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\n\u001b[1;32m    370\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    371\u001b[0m     input_tensor: tf\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     training: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    379\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[tf\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 380\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attention(\n\u001b[1;32m    381\u001b[0m         hidden_states\u001b[39m=\u001b[39;49minput_tensor,\n\u001b[1;32m    382\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    383\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    384\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    385\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    386\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    387\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    388\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m    389\u001b[0m     )\n\u001b[1;32m    390\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense_output(\n\u001b[1;32m    391\u001b[0m         hidden_states\u001b[39m=\u001b[39mself_outputs[\u001b[39m0\u001b[39m], input_tensor\u001b[39m=\u001b[39minput_tensor, training\u001b[39m=\u001b[39mtraining\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    393\u001b[0m     \u001b[39m# add attentions (possibly with past_key_value) if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/transformers/models/bert/modeling_tf_bert.py:294\u001b[0m, in \u001b[0;36mTFBertSelfAttention.call\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey(inputs\u001b[39m=\u001b[39mhidden_states), batch_size)\n\u001b[0;32m--> 294\u001b[0m     value_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue(inputs\u001b[39m=\u001b[39;49mhidden_states), batch_size)\n\u001b[1;32m    296\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(mixed_query_layer, batch_size)\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# if cross_attention save Tuple(tf.Tensor, tf.Tensor) of all cross attention key/value_states.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[39m# Further calls to cross_attention layer can then reuse all cross-attention\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[39m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001b[39;00m\n\u001b[1;32m    305\u001b[0m     \u001b[39m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/keras/src/layers/core/dense.py:244\u001b[0m, in \u001b[0;36mDense.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    241\u001b[0m         outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmatmul(a\u001b[39m=\u001b[39minputs, b\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel)\n\u001b[1;32m    242\u001b[0m \u001b[39m# Broadcast kernel to inputs.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 244\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mtensordot(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel, [[rank \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m], [\u001b[39m0\u001b[39;49m]])\n\u001b[1;32m    245\u001b[0m     \u001b[39m# Reshape the output back to the original ndim of the input.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:5194\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   5192\u001b[0m     \u001b[39mreturn\u001b[39;00m ab_matmul\n\u001b[1;32m   5193\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 5194\u001b[0m     \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39;49mreshape(\n\u001b[1;32m   5195\u001b[0m         ab_matmul, a_free_dims \u001b[39m+\u001b[39;49m b_free_dims, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   5196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5197\u001b[0m   a_free_dims \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(a_free_dims, dtype\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mint32)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:198\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmanip.reshape\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     63\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(tensor, shape, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m  \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m   result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mreshape(tensor, shape, name)\n\u001b[1;32m    199\u001b[0m   shape_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[1;32m    200\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:8571\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8569\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   8570\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 8571\u001b[0m   \u001b[39mreturn\u001b[39;00m reshape_eager_fallback(\n\u001b[1;32m   8572\u001b[0m       tensor, shape, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[1;32m   8573\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[1;32m   8574\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:8593\u001b[0m, in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   8591\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape_eager_fallback\u001b[39m(tensor, shape, name, ctx):\n\u001b[1;32m   8592\u001b[0m   _attr_T, (tensor,) \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39margs_to_matching_eager([tensor], ctx, [])\n\u001b[0;32m-> 8593\u001b[0m   _attr_Tshape, (shape,) \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49margs_to_matching_eager([shape], ctx, [_dtypes\u001b[39m.\u001b[39;49mint32, _dtypes\u001b[39m.\u001b[39;49mint64, ], _dtypes\u001b[39m.\u001b[39;49mint32)\n\u001b[1;32m   8594\u001b[0m   _inputs_flat \u001b[39m=\u001b[39m [tensor, shape]\n\u001b[1;32m   8595\u001b[0m   _attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, _attr_T, \u001b[39m\"\u001b[39m\u001b[39mTshape\u001b[39m\u001b[39m\"\u001b[39m, _attr_Tshape)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:251\u001b[0m, in \u001b[0;36margs_to_matching_eager\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39m# First see if we can get a valid dtype with the default conversion\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[39m# and see if it matches an allowed dtypes. Some ops like ConcatV2 may\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# not list allowed dtypes, in which case we should skip this.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m allowed_dtypes:\n\u001b[0;32m--> 251\u001b[0m   tensor \u001b[39m=\u001b[39m tensor_conversion_registry\u001b[39m.\u001b[39;49mconvert(t)\n\u001b[1;32m    252\u001b[0m   \u001b[39m# If we did not match an allowed dtype, try again with the default\u001b[39;00m\n\u001b[1;32m    253\u001b[0m   \u001b[39m# dtype. This could be because we have an empty tensor and thus we\u001b[39;00m\n\u001b[1;32m    254\u001b[0m   \u001b[39m# picked the wrong type.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m   \u001b[39mif\u001b[39;00m tensor\u001b[39m.\u001b[39mdtype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_dtypes:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1536\u001b[0m, in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_autopacking_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1535\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Tensor conversion function that automatically packs arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1536\u001b[0m   \u001b[39mif\u001b[39;00m as_ref \u001b[39mor\u001b[39;00m _should_not_autopack(v):\n\u001b[1;32m   1537\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m   1538\u001b[0m   inferred_dtype \u001b[39m=\u001b[39m _get_dtype_from_nested_lists(v)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1530\u001b[0m, in \u001b[0;36m_should_not_autopack\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_should_not_autopack\u001b[39m(v):\n\u001b[1;32m   1525\u001b[0m   \u001b[39m# The condition we really want is\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m   \u001b[39m#    any(isinstance(elem, core.Tensor))\u001b[39;00m\n\u001b[1;32m   1527\u001b[0m   \u001b[39m# but it is >5x slower due to abc.ABCMeta.__instancecheck__.\u001b[39;00m\n\u001b[1;32m   1528\u001b[0m   \u001b[39m# pylint: disable=unidiomatic-typecheck\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m   \u001b[39m# TODO(slebedev): add nest.all?\u001b[39;00m\n\u001b[0;32m-> 1530\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mtype\u001b[39m(elem) \u001b[39min\u001b[39;00m _NON_AUTOPACKABLE_TYPES \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m nest\u001b[39m.\u001b[39;49mflatten(v))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tensorflow/python/util/nest.py:289\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnest.flatten\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflatten\u001b[39m(structure, expand_composites\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    196\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a flat list from a given structure.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[39m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m    TypeError: The nest is or contains a dict with non-sortable keys.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m   \u001b[39mreturn\u001b[39;00m nest_util\u001b[39m.\u001b[39mflatten(\n\u001b[1;32m    290\u001b[0m       nest_util\u001b[39m.\u001b[39mModality\u001b[39m.\u001b[39mCORE, structure, expand_composites\n\u001b[1;32m    291\u001b[0m   )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Mengolah setiap baris data dengan mBERT\n",
    "df['bert_features'] = df.apply(lambda row: bert_encode(row['padded_segments'], row['attention_masks']), axis=1)\n",
    "# Rata-ratakan vektor fitur\n",
    "df['average_bert_features'] = df['bert_features'].apply(lambda x: np.mean(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21032595-f4d6-477b-9a8a-cff4c2647e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyiapkan label\n",
    "df['encoded_label'] = df['Label'].apply(lambda x: 1 if x == 'Fraud' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d850bfa-6c53-41b0-bcba-198fddd5331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
